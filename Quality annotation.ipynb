{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from rouge import rouge_score\n",
    "from itertools import combinations\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def treatment_text(text):\n",
    "    text = re.sub(\"[^а-яА-Яa-zЁёA-Z0-9,.?]\", \" \", str(text))\n",
    "    text = text.replace('\\t',' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    while text.find('  ')!=-1:\n",
    "        text = text.replace('  ',' ')\n",
    "    text = str(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "class TextRank():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pattern = \"(?u)\\\\b[\\\\w-]+\\\\b\"\n",
    "    \n",
    "            \n",
    "    def similarity_1(self,s1, s2):\n",
    "        if not len(s1) or not len(s2):\n",
    "            return 0.0\n",
    "        return len(s1.intersection(s2))/(1.0 * (len(s1) + len(s2)))\n",
    "    def similarity_2(self,s1,s2):\n",
    "        try:\n",
    "            s1 = list(s1)\n",
    "            s2 = list(s2)\n",
    "            s1 = ' '.join(map(str,s1))\n",
    "            s2 = ' '.join(map(str,s2))\n",
    "            vectorizer = CountVectorizer()\n",
    "            x = vectorizer.fit_transform([s1, s2])\n",
    "            s1_v = vectorizer.transform([s1])\n",
    "            s2_v = vectorizer.transform([s2])\n",
    "            s1 = s1_v.toarray()[0]\n",
    "            s2 = s2_v.toarray()[0]\n",
    "\n",
    "            sum = 0\n",
    "            kv1 = 0\n",
    "            kv2 = 0\n",
    "\n",
    "            for i in range(s1.shape[0]):\n",
    "                sum += s1[i] * s2[i]\n",
    "                kv1 += s1[i] * s1[i]\n",
    "                kv2 += s2[i] * s2[i]\n",
    "            kv2 = math.sqrt(kv2) + 1e-8\n",
    "            kv1 = math.sqrt(kv1) + 1e-8\n",
    "            return sum / (kv1 * kv2)\n",
    "        except: \n",
    "            return 0.0\n",
    "    \n",
    "    \n",
    "    def textrank(self,text,similar='serense'):\n",
    "        text = treatment_text(text)\n",
    "        sentences = sent_tokenize(text)\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        lmtzr = RussianStemmer()\n",
    "        words = [set(lmtzr.stem(word) for word in tokenizer.tokenize(sentence.lower()))\n",
    "                 for sentence in sentences]\n",
    "    \n",
    "        pairs = combinations(range(len(sentences)), 2)\n",
    "        if similar == 'serense':\n",
    "            scores = [(i, j, self.similarity_1(words[i], words[j])) for i, j in pairs]\n",
    "        if similar == 'cos':\n",
    "            scores = [(i, j, self.similarity_2(words[i], words[j])) for i, j in pairs]\n",
    "    \n",
    "    \n",
    "        scores = filter(lambda x: x[2], scores)\n",
    "    \n",
    "        g = nx.Graph()\n",
    "        g.add_weighted_edges_from(scores)\n",
    "        pr = nx.pagerank(g)\n",
    "    \n",
    "        return sorted(((i, pr[i], s) for i, s in enumerate(sentences) if i in pr),\n",
    "                      key=lambda x: pr[x[0]], reverse=True)\n",
    "    \n",
    "    def extract(self,text,mera='serense',n=5):\n",
    "\n",
    "        tr = self.textrank(text,similar=mera)\n",
    "        top_n = sorted(tr[:n])\n",
    "        return ' '.join(x[2] for x in top_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_true = []\n",
    "ann_pred_serense = []\n",
    "ann_pred_cos = []\n",
    "obj = TextRank()\n",
    "\n",
    "with open('./test_sample.csv','r', encoding='cp1251',newline='') as f:\n",
    "    reader = csv.reader(f,delimiter=';')\n",
    "    for i,row in enumerate(reader):\n",
    "        if row!=[]:\n",
    "            ann_pred_serense.append(obj.extract(row[2],mera='serense'))\n",
    "            ann_pred_cos.append(obj.extract(row[2],mera='cos'))\n",
    "            ann_true.append(row[1])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициентом Сёренсена \n",
      "mean precision  0.697834492620587\n",
      "mean recall     0.5579882272449521\n",
      "mean f-мера     0.5984441165439008\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "f_measure = []\n",
    "\n",
    "for i in range(len(ann_true)):\n",
    "    if len(ann_true[i].split('.'))>1 and len(ann_pred_serense[i].split('.'))>1:\n",
    "        metrics = rouge_score.rouge_n(ann_true[i], ann_pred_serense[i])\n",
    "        precision.append(metrics['p'])\n",
    "        recall.append(metrics['r'])\n",
    "        f_measure.append(metrics['f'])            \n",
    "\n",
    "\n",
    "print('Коэффициентом Сёренсена ')\n",
    "print('mean precision ',sum(precision)/len(precision))\n",
    "print('mean recall    ',sum(recall)/len(recall))\n",
    "print('mean f-мера    ',sum(f_measure)/len(f_measure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Косинусное расстояние \n",
      "mean precision  0.7240030228166541\n",
      "mean recall     0.5257838484361328\n",
      "mean f-мера     0.5838168680924231\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "f_measure = []\n",
    "\n",
    "for i in range(len(ann_true)):\n",
    "    if len(ann_true[i].split('.'))>1 and len(ann_pred_cos[i].split('.'))>1:\n",
    "        metrics = rouge_score.rouge_n(ann_true[i], ann_pred_cos[i])\n",
    "        precision.append(metrics['p'])\n",
    "        recall.append(metrics['r'])\n",
    "        f_measure.append(metrics['f'])               \n",
    "\n",
    "\n",
    "print('Косинусное расстояние ')\n",
    "print('mean precision ',sum(precision)/len(precision))\n",
    "print('mean recall    ',sum(recall)/len(recall))\n",
    "print('mean f-мера    ',sum(f_measure)/len(f_measure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
